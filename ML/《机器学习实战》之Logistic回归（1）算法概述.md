# 《机器学习实战》之Logistic回归（1）算法概述

----------

- **转载请注明作者和出处：http://blog.csdn.net/u011475210**
- **代码地址：https://github.com/WordZzzz/ML/tree/master/Ch05**
- **操作系统：WINDOWS 10**
- **软件版本：python-3.6.2-amd64**
- **编&emsp;&emsp;者：WordZzzz**

----------

[toc]

## 前言

&emsp;&emsp;其实从贝叶斯那一章开始，公式推导就渐渐多了起来，当然我在这里不是特指《机器学习实战》这本书，而是指整个机器学习的学习过程。但是为了按照原计划按时推博客（每周末推送《机器学习实战》一章的内容），所以公式推导部分相对于《机器学习实战》中对应的章节，会滞后两到三周发布。

## Logistic回归

&emsp;&emsp;Andrew在course的machine learning第三周的课程中，讲的就是logistic回归，感兴趣的朋友们可以去看看。

&emsp;&emsp;首先介绍一下什么是回归。假设现在有一些数据点，我们用一条直线对这些点进行拟合（该线称为最佳拟合直线），这个拟合过程就称作回归。利用logistic回归进行分类的主要思想是：根据现有数据对分类边界线建立回归公式，以此进行分类。这里的“回归”一词源于最佳拟合，表示要找到最佳拟合参数集。训练分类器时的做大就是寻找最佳拟合参数，实用的是最优化方法，这也是我们首次接触最优化算法。

Logistic回归的一般过程：

- 收集数据：采用任意方法收集数据。
- 准备数据：由于需要进行距离计算，因此要求数据类型为数值型。另外，结构化数据格式则最佳。
- 分析数据：采用任意方法对数据进行分析。
- 训练算法：大部分时间将用于训练，训练的目的是为了找到最佳的分类回归系数。
- 测试算法：一旦训练步骤完成，分类将会很快。
- 使用算法：首先，我们需要输入一些数据，并将其转换成对应的结构化数值；接着，基于训练好的回归系数就可以对这些数值进行简单的回归计算，判定他们属于哪个类别；在这之后，我们就可以在输出的类别上做一些其他分析工作。

## 基于Logistic回归和Sigmoid函数的分类

Logistic回归：

- 优点：计算代价不高，易于理解和实现。
- 缺点：容易欠拟合，分类精度可能不高。
- 适用数据类型：数值型和标称型数据。

&emsp;&emsp;我们想要的函数，应该是能接受所有的输入然后预测出类别。例如，在两个类的情况下，预测结果输出0或1。我们之前应该接触过类似的函数：单位阶跃函数。我的天，看书之前，我都没想起来单位阶跃函数还有个高大上的名字：海维塞德阶跃函数（Heaviside step function）。然而，单位阶跃函数的问题在于这个函数在跳跃点上从0瞬间跳跃到1，这个瞬间跳跃过程很难处理。还好，Sigmoid函数挺身而出，用于和单位阶跃函数类似的性质，但在数学上更易处理。公式如下：

`!$\sigma(z) = \frac{1}{(1 + e_{-z})}$`

&emsp;&emsp;下图给出了Sigmoid函数在不同坐标尺度下的两条曲线图。当x为0时，Sigmoid函数值为0.5.随着x的增大，对应的Sigmoid值将逼近与1；而随着x的减小，Sigmoid的值将逼近于0.如果横坐标刻度足够大，Sigmoid函数看起来很像一个单位阶跃函数。

<p></p>
<div align=center><img src="http://img.blog.csdn.net/20170917165302047?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTQ3NTIxMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"/></div>
<p></p>

&emsp;&emsp;因此，为了实现Lgistic回归分类器，我们可以在每个特征上都乘以一个回归系数，然后把所有的结果值都相加，将这个总和都带入Sigmoid()函数中，进而得到一个范围在0~1之间的数值。大于0.5则被分入1类，小于0.5则被分入0类。所以，Logistic回归也可以被看成是一种概率估计。

&emsp;&emsp;确定了分类器的函数形式之后，现在的问题成了：最佳回归系数是多少？如何确定他的大小？这些问题我们将在下一篇博文中进行讲解，包括基本的梯度上升法和一个改进的随机梯度上升法，这些最优化算法将被用于分类器的训练。

**<font color="red" size=3 face="仿宋">系列教程持续发布中，欢迎订阅、关注、收藏、评论、点赞哦～～(￣▽￣～)～</font>**

**<font color="red" size=3 face="仿宋">完的汪(∪｡∪)｡｡｡zzz</font>**