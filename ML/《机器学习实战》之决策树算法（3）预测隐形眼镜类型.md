# 《机器学习实战》之决策树算法（3）预测隐形眼镜类型

----------

- **转载请注明作者和出处：http://blog.csdn.net/u011475210**
- **代码地址：https://github.com/WordZzzz/ML/tree/master/Ch03**
- **操作系统：WINDOWS 10**
- **软件版本：python-3.6.2-amd64**
- **编&emsp;&emsp;者：WordZzzz**

----------

[toc]

## 前言：

&emsp;&emsp;本博文先介绍在实际应用中如何存储分类器，然后在实际数据上使用决策树分类算法，验证它是否可以正确预测出患者应该使用的隐形眼镜类型。

## 测试和存储算法

### 测试算法：使用决策树执行分类

&emsp;&emsp;在执行数据分类时，需要使用决策树以及用于构造决策树的标签向量。然后，程序比较测试数据与决策树上的数值，递归执行该过程知道进入叶子结点；最后将测试数据定义为叶子节点所属的类型。

代码实现：

```python
def classify(inputTree, featLabels, testVec):
	"""
	Function：	使用决策树的分类函数

	Args：		inputTree：树信息
				featLabels：标签列表
				testVec：测试数据

	Returns：	classLabel：分类标签
	"""	
	#第一个关键字为第一次划分数据集的类别标签，附带的取值表示子节点的取值
	firstStr = list(inputTree.keys())[0]
	#新的树，相当于脱了一层皮
	secondDict = inputTree[firstStr]
	#将标签字符串转为索引
	featIndex = featLabels.index(firstStr)
	#遍历整棵树
	for key in secondDict.keys():
		#比较testVec变量中的值与树节点的值
		if testVec[featIndex] == key:
			#判断子节点是否为字典类型，进而得知是否到达叶子结点
			if type(secondDict[key]).__name__=='dict':
				#没到达叶子结点，则递归调用classify()
				classLabel = classify(secondDict[key], featLabels, testVec)
			else:
				#到达叶子结点，则分类结果为当前节点的分类标签
				classLabel = secondDict[key]
	#返回分类标签
	return classLabel
```

输出结果：

```python
>>> reload(trees)
<module 'trees' from 'E:\\机器学习实战\\mycode\\Ch03\\trees.py'>
>>> myDat, labels = trees.createDataSet()
>>> labels
['no surfacing', 'flippers']
>>> myTree = treePlotter.retrieveTree(0)
>>> myTree
{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}
>>> trees.classify(myTree, labels, [1,0])
'no'
>>> trees.classify(myTree, labels, [1,1])
'yes'
```

### 使用算法：决策树的存储

&emsp;&emsp;构造决策树是很耗时的任务，及时处理很小的数据集。如果使用创建好的决策树解决分类问题，则可以很快完成。因此，为了节省计算时间，我们使用Python模块pickle序列化对象，以便在硬盘上保存和读取字典。

代码实现：：

```python
def  storeTree(inputTree, filename):
	"""
	Function：	存储决策树

	Args：		inputTree：树信息
				filename：文件名称

	Returns：	无
	"""	
	#导入模块
	import pickle
	#新建文件，一定要加b属性，否则可能报错：
	#TypeError: write() argument must be str, not bytes
	fw = open(filename, 'wb')
	#写入数据
	pickle.dump(inputTree, fw)
	#关闭文件
	fw.close()

def grabTree(filename):
	"""
	Function：	读取决策树

	Args：		filename：文件名称

	Returns：	pickle.load(fr)：树信息
	"""	
	#导入模块
	import pickle
	#打开文件，写入属性一致，否则可能报错：
	#UnicodeDecodeError: 'gbk' codec can't decode byte 0x80 in position 0: illegal multibyte sequence
	fr = open(filename, 'rb')
	#导出数据
	return pickle.load(fr)

```

输出结果：

```python
>>> reload(trees)

>>> trees.storeTree(myTree, 'classifierStorage.txt')
>>> trees.grabTree('classifierStorage.txt')
{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}
```

&emsp;&emsp;通过上面的代码，我们可以将分类器存储在硬盘上，而不用每次对数据分类时重新学习一遍，这也是决策树的优点之一，而k-近邻算法却无法持久化分类器。

## 使用决策树预测隐形眼镜类型：

示例：使用决策树预测隐形眼镜类型：

- 收集数据：提供的文本文件。
- 准备数据：解析tab键分割的数据行。
- 分析数据：快速检查数据，确保正确地解析数据内容，使用createPlot()函数绘制最终的树形图。
- 训练算法：使用前面编写好的createTree()函数。
- 测试算法：编写测试函数验证决策树科一正确分类给定的数据实例。
- 使用算法：存储树的数据结构，以便下次使用时无需重新构造树。

&emsp;&emsp;隐形眼镜数据集是非常著名的数据集，它包含很多患者眼部状况的观察条件以及医生推荐的隐形眼镜类型，数据来源于UCI数据库，为了更容易显示数据，书中对数据做了简单的更改，即lenses.txt文件。

```python
>>> fr = open('lenses.txt')
>>> lenses = [inst.strip().split('\t') for inst in fr.readlines()]
>>> lensesLabels = ['age', 'prescript', 'astigmatic', 'tearRate']
>>> import trees
>>> lensesTree = trees.createTree(lenses, lensesLabels)
>>> lensesTree
{'tearRate': {'reduced': 'no lenses', 'normal': {'astigmatic': {'yes': {'prescript': {'myope': 'hard', 'hyper': {'age': {'pre': 'no lenses', 'young': 'hard', 'presbyopic': 'no lenses'}}}}, 'no': {'age': {'pre': 'soft', 'young': 'soft', 'presbyopic': {'prescript': {'myope': 'no lenses', 'hyper': 'soft'}}}}}}}}
>>> import treePlotter
>>> treePlotter.createPlot(lensesTree)
```

&emsp;&emsp;本渣渣将上述代码包装成函数，方便大家直接调用。

代码实现：

```python
# -*- coding: UTF-8 -*-
"""
Created on Aug 31, 2017
Test on the modules
@author: wordzzzz
"""
import trees
import treePlotter

def main():
	"""
	Function：	主函数

	Args：		无

	Returns：	无
	"""
	#打开文件
	fr = open('lenses.txt')
	#读取文件信息
	lenses = [inst.strip().split('\t') for inst in fr.readlines()]
	#定义标签
	lensesLabels = ['age', 'prescript', 'astigmatic', 'tearRate']
	#创建树
	lensesTree = trees.createTree(lenses, lensesLabels)
	#打印树信息
	print(lensesTree)
	#绘制树信息
	treePlotter.createPlot(lensesTree)

if __name__ == "__main__":
	main()
```

输出结果：

```python
E:\机器学习实战\mycode\Ch03>python3 test.py
{'tearRate': {'reduced': 'no lenses', 'normal': {'astigmatic': {'no': {'age': {'presbyopic': {'prescript': {'myope': 'no lenses', 'hyper': 'soft'}}, 'young': 'soft', 'pre': 'soft'}}, 'yes': {'prescript': {'myope': 'hard', 'hyper': {'age': {'presbyopic': 'no lenses', 'young': 'hard', 'pre': 'no lenses'}}}}}}}}
```

<p></p>
<div align=center><img src="http://img.blog.csdn.net/20170903220008361?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTQ3NTIxMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"/></div>
<p></p>

&emsp;&emsp;隐形眼睛的例子表明决策树可能会产生过多的数据集划分，从而产生过度匹配数据集的问题。我们可以通过裁剪决策树，合并相邻的无法产生大量信息增益的叶节点，消除过度匹配问题。淡然还有很多决策树构造算法，最流行的是C4.5和CART。

**<font color="red" size=3 face="仿宋">系列教程持续发布中，欢迎订阅、关注、收藏、评论、点赞哦～～(￣▽￣～)～</font>**

**<font color="red" size=3 face="仿宋">完的汪(∪｡∪)｡｡｡zzz</font>**